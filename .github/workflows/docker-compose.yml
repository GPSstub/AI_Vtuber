
# CUDA 개발 환경을 사용하여 의존성을 빌드
FROM nvidia/cuda:12.4.1-devel-ubuntu22.04 AS builder

ENV TZ=Etc/UTC

# 시스템 업데이트 및 빌드에 필요한 모든 도구 설치
RUN apt-get update && apt-get install -y --no-install-recommends \
    build-essential \
    cmake \
    autoconf \
    automake \
    pkg-config \
    python3.10 \
    python3.10-dev \
    python3.10-venv \
    python3-pip \
    && rm -rf /var/lib/apt/lists/*

# 가상 환경 생성 및 활성화
RUN python3.10 -m venv /opt/venv
ENV PATH="/opt/venv/bin:$PATH"

# llama-cpp-python을 CUDA 지원으로 빌드하기 위한 환경 변수 설정
ENV CMAKE_ARGS="-DGGML_CUDA=on"
ENV FORCE_CMAKE=1
ENV LDFLAGS="-L/usr/local/cuda/lib64/stubs"

# Link the CUDA stub library to a place where the linker can find it.
RUN ln -s /usr/local/cuda/lib64/stubs/libcuda.so /usr/lib/x86_64-linux-gnu/libcuda.so.1

# requirements.txt
# llama-cpp-python 소스에서 컴파일 !!!중요!!!
COPY requirements.txt .
RUN pip install --no-cache-dir --no-binary=llama-cpp-python -r requirements.txt



# CUDA
FROM nvidia/cuda:12.4.1-runtime-ubuntu22.04

ENV TZ=Etc/UTC

# 런타임에 필요한 라이브러리 설치
RUN apt-get update && apt-get install -y --no-install-recommends \
    python3.10 \
    libsndfile1 \
    libgomp1 \
    && rm -rf /var/lib/apt/lists/*

# 가상 환경 복사 
COPY --from=builder /opt/venv /opt/venv

# app 안에서 사용을 위한 워크디렉토리 선언 및 지정 
WORKDIR /app
ENV PATH="/opt/venv/bin:$PATH"

# 애플리케이션 소스 코드 복사
COPY . .

# Python 로그 설정 버퍼를 표시해라
ENV PYTHONUNBUFFERED=1

# FastAPI 용 포트 노출 
EXPOSE 8000

# 컨테이너 실행 uvicorn 서버를 시작
CMD ["python", "-m", "uvicorn", "main_app:app", "--host", "0.0.0.0", "--port", "8000"]
