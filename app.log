[2025-07-07 13:05:24][ERROR] [환경 오류] ffmpeg가 설치되어 있지 않습니다. https://ffmpeg.org/download.html 에서 설치 후 PATH에 추가하세요.
[2025-07-07 13:06:59][ERROR] [환경 오류] ffmpeg가 설치되어 있지 않습니다. https://ffmpeg.org/download.html 에서 설치 후 PATH에 추가하세요.
[2025-07-07 13:11:35][ERROR] [환경 오류] ffmpeg가 설치되어 있지 않습니다. https://ffmpeg.org/download.html 에서 설치 후 PATH에 추가하세요.
[2025-07-07 13:13:12][ERROR] [환경 오류] ffmpeg가 설치되어 있지 않습니다. https://ffmpeg.org/download.html 에서 설치 후 PATH에 추가하세요.
[2025-07-07 13:14:02][ERROR] [환경 오류] ffmpeg가 설치되어 있지 않습니다. https://ffmpeg.org/download.html 에서 설치 후 PATH에 추가하세요.
[2025-07-07 13:16:57][INFO] [환경 체크] 필수 의존성 및 설정 확인 완료.
[2025-07-07 13:16:57][INFO] 모든 AI 모델을 로드합니다. 시간이 걸릴 수 있습니다...
[2025-07-07 13:17:00][ERROR] 모델 로드 중 심각한 오류 발생: No module named 'torchaudio'
[2025-07-07 13:17:29][INFO] [환경 체크] 필수 의존성 및 설정 확인 완료.
[2025-07-07 13:17:29][INFO] 모든 AI 모델을 로드합니다. 시간이 걸릴 수 있습니다...
[2025-07-07 13:17:30][ERROR] 모델 로드 중 심각한 오류 발생: No module named 'torchaudio'
[2025-07-07 13:18:32][INFO] [환경 체크] 필수 의존성 및 설정 확인 완료.
[2025-07-07 13:18:32][INFO] 모든 AI 모델을 로드합니다. 시간이 걸릴 수 있습니다...
[2025-07-07 13:18:33][INFO] 1/5 - Silero VAD 모델 로드 완료.
[2025-07-07 13:18:36][INFO] 2/5 - Whisper STT 모델 로드 완료.
[2025-07-07 13:18:44][INFO] 3/5 - 감정 분석(Fast) 모델 로드 완료.
[2025-07-07 13:19:08][INFO] 4/5 - 감정 분석(Precise) 모델 로드 완료.
[2025-07-07 13:19:08][INFO] 5/5 - 로컬 LLM 모델 로드 완료.
[2025-07-07 13:19:08][INFO] --- 모든 모델 로드 완료 ---
[2025-07-07 13:19:08][INFO] 
>>> AI VTuber가 당신의 말을 듣고 있습니다... <<<
[2025-07-07 13:19:08][ERROR] [스레드 오류] recording_thread_func에서 예외 발생, 3초 후 재시작: The following operation failed in the TorchScript interpreter.
Traceback of TorchScript, serialized code (most recent call last):
  File "code/__torch__/vad/model/vad_annotator.py", line 26, in forward
    if _2:
      _3 = torch.format(_0, (torch.size(x0))[-1])
      ops.prim.RaiseException(_3, "builtins.ValueError")
      ~~~~~~~~~~~~~~~~~~~~~~~ <--- HERE
    else:
      pass

Traceback of TorchScript, original code (most recent call last):
  File "/home/keras/notebook/nvme1/adamnsandle/silero-models-research/vad/model/vad_annotator.py", line 480, in forward
        num_samples = 512 if sr == 16000 else 256
        if x.shape[-1] != num_samples:
            raise ValueError(f"Provided number of samples is {x.shape[-1]} (Supported values: 256 for 8000 sample rate, 512 for 16000)")
            ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ <--- HERE
    
        batch_size = x.shape[0]
builtins.ValueError: Provided number of samples is 1024 (Supported values: 256 for 8000 sample rate, 512 for 16000)

[2025-07-07 13:19:11][INFO] 
>>> AI VTuber가 당신의 말을 듣고 있습니다... <<<
[2025-07-07 13:19:11][ERROR] [스레드 오류] recording_thread_func에서 예외 발생, 3초 후 재시작: The following operation failed in the TorchScript interpreter.
Traceback of TorchScript, serialized code (most recent call last):
  File "code/__torch__/vad/model/vad_annotator.py", line 26, in forward
    if _2:
      _3 = torch.format(_0, (torch.size(x0))[-1])
      ops.prim.RaiseException(_3, "builtins.ValueError")
      ~~~~~~~~~~~~~~~~~~~~~~~ <--- HERE
    else:
      pass

Traceback of TorchScript, original code (most recent call last):
  File "/home/keras/notebook/nvme1/adamnsandle/silero-models-research/vad/model/vad_annotator.py", line 480, in forward
        num_samples = 512 if sr == 16000 else 256
        if x.shape[-1] != num_samples:
            raise ValueError(f"Provided number of samples is {x.shape[-1]} (Supported values: 256 for 8000 sample rate, 512 for 16000)")
            ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ <--- HERE
    
        batch_size = x.shape[0]
builtins.ValueError: Provided number of samples is 1024 (Supported values: 256 for 8000 sample rate, 512 for 16000)

[2025-07-07 13:19:14][INFO] 
>>> AI VTuber가 당신의 말을 듣고 있습니다... <<<
[2025-07-07 13:19:14][ERROR] [스레드 오류] recording_thread_func에서 예외 발생, 3초 후 재시작: The following operation failed in the TorchScript interpreter.
Traceback of TorchScript, serialized code (most recent call last):
  File "code/__torch__/vad/model/vad_annotator.py", line 26, in forward
    if _2:
      _3 = torch.format(_0, (torch.size(x0))[-1])
      ops.prim.RaiseException(_3, "builtins.ValueError")
      ~~~~~~~~~~~~~~~~~~~~~~~ <--- HERE
    else:
      pass

Traceback of TorchScript, original code (most recent call last):
  File "/home/keras/notebook/nvme1/adamnsandle/silero-models-research/vad/model/vad_annotator.py", line 480, in forward
        num_samples = 512 if sr == 16000 else 256
        if x.shape[-1] != num_samples:
            raise ValueError(f"Provided number of samples is {x.shape[-1]} (Supported values: 256 for 8000 sample rate, 512 for 16000)")
            ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ <--- HERE
    
        batch_size = x.shape[0]
builtins.ValueError: Provided number of samples is 1024 (Supported values: 256 for 8000 sample rate, 512 for 16000)

[2025-07-07 13:19:17][INFO] 
>>> AI VTuber가 당신의 말을 듣고 있습니다... <<<
[2025-07-07 13:19:17][ERROR] [스레드 오류] recording_thread_func에서 예외 발생, 3초 후 재시작: The following operation failed in the TorchScript interpreter.
Traceback of TorchScript, serialized code (most recent call last):
  File "code/__torch__/vad/model/vad_annotator.py", line 26, in forward
    if _2:
      _3 = torch.format(_0, (torch.size(x0))[-1])
      ops.prim.RaiseException(_3, "builtins.ValueError")
      ~~~~~~~~~~~~~~~~~~~~~~~ <--- HERE
    else:
      pass

Traceback of TorchScript, original code (most recent call last):
  File "/home/keras/notebook/nvme1/adamnsandle/silero-models-research/vad/model/vad_annotator.py", line 480, in forward
        num_samples = 512 if sr == 16000 else 256
        if x.shape[-1] != num_samples:
            raise ValueError(f"Provided number of samples is {x.shape[-1]} (Supported values: 256 for 8000 sample rate, 512 for 16000)")
            ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ <--- HERE
    
        batch_size = x.shape[0]
builtins.ValueError: Provided number of samples is 1024 (Supported values: 256 for 8000 sample rate, 512 for 16000)

[2025-07-07 13:19:20][INFO] 
>>> AI VTuber가 당신의 말을 듣고 있습니다... <<<
[2025-07-07 13:19:20][ERROR] [스레드 오류] recording_thread_func에서 예외 발생, 3초 후 재시작: The following operation failed in the TorchScript interpreter.
Traceback of TorchScript, serialized code (most recent call last):
  File "code/__torch__/vad/model/vad_annotator.py", line 26, in forward
    if _2:
      _3 = torch.format(_0, (torch.size(x0))[-1])
      ops.prim.RaiseException(_3, "builtins.ValueError")
      ~~~~~~~~~~~~~~~~~~~~~~~ <--- HERE
    else:
      pass

Traceback of TorchScript, original code (most recent call last):
  File "/home/keras/notebook/nvme1/adamnsandle/silero-models-research/vad/model/vad_annotator.py", line 480, in forward
        num_samples = 512 if sr == 16000 else 256
        if x.shape[-1] != num_samples:
            raise ValueError(f"Provided number of samples is {x.shape[-1]} (Supported values: 256 for 8000 sample rate, 512 for 16000)")
            ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ <--- HERE
    
        batch_size = x.shape[0]
builtins.ValueError: Provided number of samples is 1024 (Supported values: 256 for 8000 sample rate, 512 for 16000)

[2025-07-07 13:19:23][INFO] 
>>> AI VTuber가 당신의 말을 듣고 있습니다... <<<
[2025-07-07 13:19:23][ERROR] [스레드 오류] recording_thread_func에서 예외 발생, 3초 후 재시작: The following operation failed in the TorchScript interpreter.
Traceback of TorchScript, serialized code (most recent call last):
  File "code/__torch__/vad/model/vad_annotator.py", line 26, in forward
    if _2:
      _3 = torch.format(_0, (torch.size(x0))[-1])
      ops.prim.RaiseException(_3, "builtins.ValueError")
      ~~~~~~~~~~~~~~~~~~~~~~~ <--- HERE
    else:
      pass

Traceback of TorchScript, original code (most recent call last):
  File "/home/keras/notebook/nvme1/adamnsandle/silero-models-research/vad/model/vad_annotator.py", line 480, in forward
        num_samples = 512 if sr == 16000 else 256
        if x.shape[-1] != num_samples:
            raise ValueError(f"Provided number of samples is {x.shape[-1]} (Supported values: 256 for 8000 sample rate, 512 for 16000)")
            ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ <--- HERE
    
        batch_size = x.shape[0]
builtins.ValueError: Provided number of samples is 1024 (Supported values: 256 for 8000 sample rate, 512 for 16000)

[2025-07-07 13:19:26][INFO] 
>>> AI VTuber가 당신의 말을 듣고 있습니다... <<<
[2025-07-07 13:19:26][ERROR] [스레드 오류] recording_thread_func에서 예외 발생, 3초 후 재시작: The following operation failed in the TorchScript interpreter.
Traceback of TorchScript, serialized code (most recent call last):
  File "code/__torch__/vad/model/vad_annotator.py", line 26, in forward
    if _2:
      _3 = torch.format(_0, (torch.size(x0))[-1])
      ops.prim.RaiseException(_3, "builtins.ValueError")
      ~~~~~~~~~~~~~~~~~~~~~~~ <--- HERE
    else:
      pass

Traceback of TorchScript, original code (most recent call last):
  File "/home/keras/notebook/nvme1/adamnsandle/silero-models-research/vad/model/vad_annotator.py", line 480, in forward
        num_samples = 512 if sr == 16000 else 256
        if x.shape[-1] != num_samples:
            raise ValueError(f"Provided number of samples is {x.shape[-1]} (Supported values: 256 for 8000 sample rate, 512 for 16000)")
            ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ <--- HERE
    
        batch_size = x.shape[0]
builtins.ValueError: Provided number of samples is 1024 (Supported values: 256 for 8000 sample rate, 512 for 16000)

[2025-07-07 13:19:29][INFO] 
>>> AI VTuber가 당신의 말을 듣고 있습니다... <<<
[2025-07-07 13:19:30][ERROR] [스레드 오류] recording_thread_func에서 예외 발생, 3초 후 재시작: The following operation failed in the TorchScript interpreter.
Traceback of TorchScript, serialized code (most recent call last):
  File "code/__torch__/vad/model/vad_annotator.py", line 26, in forward
    if _2:
      _3 = torch.format(_0, (torch.size(x0))[-1])
      ops.prim.RaiseException(_3, "builtins.ValueError")
      ~~~~~~~~~~~~~~~~~~~~~~~ <--- HERE
    else:
      pass

Traceback of TorchScript, original code (most recent call last):
  File "/home/keras/notebook/nvme1/adamnsandle/silero-models-research/vad/model/vad_annotator.py", line 480, in forward
        num_samples = 512 if sr == 16000 else 256
        if x.shape[-1] != num_samples:
            raise ValueError(f"Provided number of samples is {x.shape[-1]} (Supported values: 256 for 8000 sample rate, 512 for 16000)")
            ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ <--- HERE
    
        batch_size = x.shape[0]
builtins.ValueError: Provided number of samples is 1024 (Supported values: 256 for 8000 sample rate, 512 for 16000)

[2025-07-07 13:19:33][INFO] 
>>> AI VTuber가 당신의 말을 듣고 있습니다... <<<
[2025-07-07 13:19:33][ERROR] [스레드 오류] recording_thread_func에서 예외 발생, 3초 후 재시작: The following operation failed in the TorchScript interpreter.
Traceback of TorchScript, serialized code (most recent call last):
  File "code/__torch__/vad/model/vad_annotator.py", line 26, in forward
    if _2:
      _3 = torch.format(_0, (torch.size(x0))[-1])
      ops.prim.RaiseException(_3, "builtins.ValueError")
      ~~~~~~~~~~~~~~~~~~~~~~~ <--- HERE
    else:
      pass

Traceback of TorchScript, original code (most recent call last):
  File "/home/keras/notebook/nvme1/adamnsandle/silero-models-research/vad/model/vad_annotator.py", line 480, in forward
        num_samples = 512 if sr == 16000 else 256
        if x.shape[-1] != num_samples:
            raise ValueError(f"Provided number of samples is {x.shape[-1]} (Supported values: 256 for 8000 sample rate, 512 for 16000)")
            ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ <--- HERE
    
        batch_size = x.shape[0]
builtins.ValueError: Provided number of samples is 1024 (Supported values: 256 for 8000 sample rate, 512 for 16000)

[2025-07-07 13:19:36][INFO] 
>>> AI VTuber가 당신의 말을 듣고 있습니다... <<<
[2025-07-07 13:19:36][ERROR] [스레드 오류] recording_thread_func에서 예외 발생, 3초 후 재시작: The following operation failed in the TorchScript interpreter.
Traceback of TorchScript, serialized code (most recent call last):
  File "code/__torch__/vad/model/vad_annotator.py", line 26, in forward
    if _2:
      _3 = torch.format(_0, (torch.size(x0))[-1])
      ops.prim.RaiseException(_3, "builtins.ValueError")
      ~~~~~~~~~~~~~~~~~~~~~~~ <--- HERE
    else:
      pass

Traceback of TorchScript, original code (most recent call last):
  File "/home/keras/notebook/nvme1/adamnsandle/silero-models-research/vad/model/vad_annotator.py", line 480, in forward
        num_samples = 512 if sr == 16000 else 256
        if x.shape[-1] != num_samples:
            raise ValueError(f"Provided number of samples is {x.shape[-1]} (Supported values: 256 for 8000 sample rate, 512 for 16000)")
            ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ <--- HERE
    
        batch_size = x.shape[0]
builtins.ValueError: Provided number of samples is 1024 (Supported values: 256 for 8000 sample rate, 512 for 16000)

[2025-07-07 13:19:39][INFO] 
>>> AI VTuber가 당신의 말을 듣고 있습니다... <<<
[2025-07-07 13:19:39][ERROR] [스레드 오류] recording_thread_func에서 예외 발생, 3초 후 재시작: The following operation failed in the TorchScript interpreter.
Traceback of TorchScript, serialized code (most recent call last):
  File "code/__torch__/vad/model/vad_annotator.py", line 26, in forward
    if _2:
      _3 = torch.format(_0, (torch.size(x0))[-1])
      ops.prim.RaiseException(_3, "builtins.ValueError")
      ~~~~~~~~~~~~~~~~~~~~~~~ <--- HERE
    else:
      pass

Traceback of TorchScript, original code (most recent call last):
  File "/home/keras/notebook/nvme1/adamnsandle/silero-models-research/vad/model/vad_annotator.py", line 480, in forward
        num_samples = 512 if sr == 16000 else 256
        if x.shape[-1] != num_samples:
            raise ValueError(f"Provided number of samples is {x.shape[-1]} (Supported values: 256 for 8000 sample rate, 512 for 16000)")
            ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ <--- HERE
    
        batch_size = x.shape[0]
builtins.ValueError: Provided number of samples is 1024 (Supported values: 256 for 8000 sample rate, 512 for 16000)

[2025-07-07 13:19:42][INFO] 
>>> AI VTuber가 당신의 말을 듣고 있습니다... <<<
[2025-07-07 13:19:42][ERROR] [스레드 오류] recording_thread_func에서 예외 발생, 3초 후 재시작: The following operation failed in the TorchScript interpreter.
Traceback of TorchScript, serialized code (most recent call last):
  File "code/__torch__/vad/model/vad_annotator.py", line 26, in forward
    if _2:
      _3 = torch.format(_0, (torch.size(x0))[-1])
      ops.prim.RaiseException(_3, "builtins.ValueError")
      ~~~~~~~~~~~~~~~~~~~~~~~ <--- HERE
    else:
      pass

Traceback of TorchScript, original code (most recent call last):
  File "/home/keras/notebook/nvme1/adamnsandle/silero-models-research/vad/model/vad_annotator.py", line 480, in forward
        num_samples = 512 if sr == 16000 else 256
        if x.shape[-1] != num_samples:
            raise ValueError(f"Provided number of samples is {x.shape[-1]} (Supported values: 256 for 8000 sample rate, 512 for 16000)")
            ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ <--- HERE
    
        batch_size = x.shape[0]
builtins.ValueError: Provided number of samples is 1024 (Supported values: 256 for 8000 sample rate, 512 for 16000)

[2025-07-07 13:19:45][INFO] 
>>> AI VTuber가 당신의 말을 듣고 있습니다... <<<
[2025-07-07 13:19:45][ERROR] [스레드 오류] recording_thread_func에서 예외 발생, 3초 후 재시작: The following operation failed in the TorchScript interpreter.
Traceback of TorchScript, serialized code (most recent call last):
  File "code/__torch__/vad/model/vad_annotator.py", line 26, in forward
    if _2:
      _3 = torch.format(_0, (torch.size(x0))[-1])
      ops.prim.RaiseException(_3, "builtins.ValueError")
      ~~~~~~~~~~~~~~~~~~~~~~~ <--- HERE
    else:
      pass

Traceback of TorchScript, original code (most recent call last):
  File "/home/keras/notebook/nvme1/adamnsandle/silero-models-research/vad/model/vad_annotator.py", line 480, in forward
        num_samples = 512 if sr == 16000 else 256
        if x.shape[-1] != num_samples:
            raise ValueError(f"Provided number of samples is {x.shape[-1]} (Supported values: 256 for 8000 sample rate, 512 for 16000)")
            ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ <--- HERE
    
        batch_size = x.shape[0]
builtins.ValueError: Provided number of samples is 1024 (Supported values: 256 for 8000 sample rate, 512 for 16000)

[2025-07-07 13:19:48][INFO] 
>>> AI VTuber가 당신의 말을 듣고 있습니다... <<<
[2025-07-07 13:19:48][ERROR] [스레드 오류] recording_thread_func에서 예외 발생, 3초 후 재시작: The following operation failed in the TorchScript interpreter.
Traceback of TorchScript, serialized code (most recent call last):
  File "code/__torch__/vad/model/vad_annotator.py", line 26, in forward
    if _2:
      _3 = torch.format(_0, (torch.size(x0))[-1])
      ops.prim.RaiseException(_3, "builtins.ValueError")
      ~~~~~~~~~~~~~~~~~~~~~~~ <--- HERE
    else:
      pass

Traceback of TorchScript, original code (most recent call last):
  File "/home/keras/notebook/nvme1/adamnsandle/silero-models-research/vad/model/vad_annotator.py", line 480, in forward
        num_samples = 512 if sr == 16000 else 256
        if x.shape[-1] != num_samples:
            raise ValueError(f"Provided number of samples is {x.shape[-1]} (Supported values: 256 for 8000 sample rate, 512 for 16000)")
            ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ <--- HERE
    
        batch_size = x.shape[0]
builtins.ValueError: Provided number of samples is 1024 (Supported values: 256 for 8000 sample rate, 512 for 16000)

[2025-07-07 13:19:51][INFO] 
>>> AI VTuber가 당신의 말을 듣고 있습니다... <<<
[2025-07-07 13:19:51][ERROR] [스레드 오류] recording_thread_func에서 예외 발생, 3초 후 재시작: The following operation failed in the TorchScript interpreter.
Traceback of TorchScript, serialized code (most recent call last):
  File "code/__torch__/vad/model/vad_annotator.py", line 26, in forward
    if _2:
      _3 = torch.format(_0, (torch.size(x0))[-1])
      ops.prim.RaiseException(_3, "builtins.ValueError")
      ~~~~~~~~~~~~~~~~~~~~~~~ <--- HERE
    else:
      pass

Traceback of TorchScript, original code (most recent call last):
  File "/home/keras/notebook/nvme1/adamnsandle/silero-models-research/vad/model/vad_annotator.py", line 480, in forward
        num_samples = 512 if sr == 16000 else 256
        if x.shape[-1] != num_samples:
            raise ValueError(f"Provided number of samples is {x.shape[-1]} (Supported values: 256 for 8000 sample rate, 512 for 16000)")
            ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ <--- HERE
    
        batch_size = x.shape[0]
builtins.ValueError: Provided number of samples is 1024 (Supported values: 256 for 8000 sample rate, 512 for 16000)

[2025-07-07 13:19:54][INFO] 
>>> AI VTuber가 당신의 말을 듣고 있습니다... <<<
[2025-07-07 13:19:54][ERROR] [스레드 오류] recording_thread_func에서 예외 발생, 3초 후 재시작: The following operation failed in the TorchScript interpreter.
Traceback of TorchScript, serialized code (most recent call last):
  File "code/__torch__/vad/model/vad_annotator.py", line 26, in forward
    if _2:
      _3 = torch.format(_0, (torch.size(x0))[-1])
      ops.prim.RaiseException(_3, "builtins.ValueError")
      ~~~~~~~~~~~~~~~~~~~~~~~ <--- HERE
    else:
      pass

Traceback of TorchScript, original code (most recent call last):
  File "/home/keras/notebook/nvme1/adamnsandle/silero-models-research/vad/model/vad_annotator.py", line 480, in forward
        num_samples = 512 if sr == 16000 else 256
        if x.shape[-1] != num_samples:
            raise ValueError(f"Provided number of samples is {x.shape[-1]} (Supported values: 256 for 8000 sample rate, 512 for 16000)")
            ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ <--- HERE
    
        batch_size = x.shape[0]
builtins.ValueError: Provided number of samples is 1024 (Supported values: 256 for 8000 sample rate, 512 for 16000)

[2025-07-07 13:19:57][INFO] 
>>> AI VTuber가 당신의 말을 듣고 있습니다... <<<
[2025-07-07 13:19:58][ERROR] [스레드 오류] recording_thread_func에서 예외 발생, 3초 후 재시작: The following operation failed in the TorchScript interpreter.
Traceback of TorchScript, serialized code (most recent call last):
  File "code/__torch__/vad/model/vad_annotator.py", line 26, in forward
    if _2:
      _3 = torch.format(_0, (torch.size(x0))[-1])
      ops.prim.RaiseException(_3, "builtins.ValueError")
      ~~~~~~~~~~~~~~~~~~~~~~~ <--- HERE
    else:
      pass

Traceback of TorchScript, original code (most recent call last):
  File "/home/keras/notebook/nvme1/adamnsandle/silero-models-research/vad/model/vad_annotator.py", line 480, in forward
        num_samples = 512 if sr == 16000 else 256
        if x.shape[-1] != num_samples:
            raise ValueError(f"Provided number of samples is {x.shape[-1]} (Supported values: 256 for 8000 sample rate, 512 for 16000)")
            ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ <--- HERE
    
        batch_size = x.shape[0]
builtins.ValueError: Provided number of samples is 1024 (Supported values: 256 for 8000 sample rate, 512 for 16000)

[2025-07-07 13:20:01][INFO] 
>>> AI VTuber가 당신의 말을 듣고 있습니다... <<<
[2025-07-07 13:20:01][ERROR] [스레드 오류] recording_thread_func에서 예외 발생, 3초 후 재시작: The following operation failed in the TorchScript interpreter.
Traceback of TorchScript, serialized code (most recent call last):
  File "code/__torch__/vad/model/vad_annotator.py", line 26, in forward
    if _2:
      _3 = torch.format(_0, (torch.size(x0))[-1])
      ops.prim.RaiseException(_3, "builtins.ValueError")
      ~~~~~~~~~~~~~~~~~~~~~~~ <--- HERE
    else:
      pass

Traceback of TorchScript, original code (most recent call last):
  File "/home/keras/notebook/nvme1/adamnsandle/silero-models-research/vad/model/vad_annotator.py", line 480, in forward
        num_samples = 512 if sr == 16000 else 256
        if x.shape[-1] != num_samples:
            raise ValueError(f"Provided number of samples is {x.shape[-1]} (Supported values: 256 for 8000 sample rate, 512 for 16000)")
            ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ <--- HERE
    
        batch_size = x.shape[0]
builtins.ValueError: Provided number of samples is 1024 (Supported values: 256 for 8000 sample rate, 512 for 16000)

[2025-07-07 13:20:04][INFO] 
>>> AI VTuber가 당신의 말을 듣고 있습니다... <<<
[2025-07-07 13:20:04][ERROR] [스레드 오류] recording_thread_func에서 예외 발생, 3초 후 재시작: The following operation failed in the TorchScript interpreter.
Traceback of TorchScript, serialized code (most recent call last):
  File "code/__torch__/vad/model/vad_annotator.py", line 26, in forward
    if _2:
      _3 = torch.format(_0, (torch.size(x0))[-1])
      ops.prim.RaiseException(_3, "builtins.ValueError")
      ~~~~~~~~~~~~~~~~~~~~~~~ <--- HERE
    else:
      pass

Traceback of TorchScript, original code (most recent call last):
  File "/home/keras/notebook/nvme1/adamnsandle/silero-models-research/vad/model/vad_annotator.py", line 480, in forward
        num_samples = 512 if sr == 16000 else 256
        if x.shape[-1] != num_samples:
            raise ValueError(f"Provided number of samples is {x.shape[-1]} (Supported values: 256 for 8000 sample rate, 512 for 16000)")
            ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ <--- HERE
    
        batch_size = x.shape[0]
builtins.ValueError: Provided number of samples is 1024 (Supported values: 256 for 8000 sample rate, 512 for 16000)

[2025-07-07 13:20:07][INFO] 
>>> AI VTuber가 당신의 말을 듣고 있습니다... <<<
[2025-07-07 13:20:07][ERROR] [스레드 오류] recording_thread_func에서 예외 발생, 3초 후 재시작: The following operation failed in the TorchScript interpreter.
Traceback of TorchScript, serialized code (most recent call last):
  File "code/__torch__/vad/model/vad_annotator.py", line 26, in forward
    if _2:
      _3 = torch.format(_0, (torch.size(x0))[-1])
      ops.prim.RaiseException(_3, "builtins.ValueError")
      ~~~~~~~~~~~~~~~~~~~~~~~ <--- HERE
    else:
      pass

Traceback of TorchScript, original code (most recent call last):
  File "/home/keras/notebook/nvme1/adamnsandle/silero-models-research/vad/model/vad_annotator.py", line 480, in forward
        num_samples = 512 if sr == 16000 else 256
        if x.shape[-1] != num_samples:
            raise ValueError(f"Provided number of samples is {x.shape[-1]} (Supported values: 256 for 8000 sample rate, 512 for 16000)")
            ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ <--- HERE
    
        batch_size = x.shape[0]
builtins.ValueError: Provided number of samples is 1024 (Supported values: 256 for 8000 sample rate, 512 for 16000)

[2025-07-07 13:20:10][INFO] 
>>> AI VTuber가 당신의 말을 듣고 있습니다... <<<
[2025-07-07 13:20:10][ERROR] [스레드 오류] recording_thread_func에서 예외 발생, 3초 후 재시작: The following operation failed in the TorchScript interpreter.
Traceback of TorchScript, serialized code (most recent call last):
  File "code/__torch__/vad/model/vad_annotator.py", line 26, in forward
    if _2:
      _3 = torch.format(_0, (torch.size(x0))[-1])
      ops.prim.RaiseException(_3, "builtins.ValueError")
      ~~~~~~~~~~~~~~~~~~~~~~~ <--- HERE
    else:
      pass

Traceback of TorchScript, original code (most recent call last):
  File "/home/keras/notebook/nvme1/adamnsandle/silero-models-research/vad/model/vad_annotator.py", line 480, in forward
        num_samples = 512 if sr == 16000 else 256
        if x.shape[-1] != num_samples:
            raise ValueError(f"Provided number of samples is {x.shape[-1]} (Supported values: 256 for 8000 sample rate, 512 for 16000)")
            ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ <--- HERE
    
        batch_size = x.shape[0]
builtins.ValueError: Provided number of samples is 1024 (Supported values: 256 for 8000 sample rate, 512 for 16000)

[2025-07-07 13:20:13][INFO] 
>>> AI VTuber가 당신의 말을 듣고 있습니다... <<<
[2025-07-07 13:20:13][ERROR] [스레드 오류] recording_thread_func에서 예외 발생, 3초 후 재시작: The following operation failed in the TorchScript interpreter.
Traceback of TorchScript, serialized code (most recent call last):
  File "code/__torch__/vad/model/vad_annotator.py", line 26, in forward
    if _2:
      _3 = torch.format(_0, (torch.size(x0))[-1])
      ops.prim.RaiseException(_3, "builtins.ValueError")
      ~~~~~~~~~~~~~~~~~~~~~~~ <--- HERE
    else:
      pass

Traceback of TorchScript, original code (most recent call last):
  File "/home/keras/notebook/nvme1/adamnsandle/silero-models-research/vad/model/vad_annotator.py", line 480, in forward
        num_samples = 512 if sr == 16000 else 256
        if x.shape[-1] != num_samples:
            raise ValueError(f"Provided number of samples is {x.shape[-1]} (Supported values: 256 for 8000 sample rate, 512 for 16000)")
            ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ <--- HERE
    
        batch_size = x.shape[0]
builtins.ValueError: Provided number of samples is 1024 (Supported values: 256 for 8000 sample rate, 512 for 16000)

[2025-07-07 13:20:16][INFO] 
>>> AI VTuber가 당신의 말을 듣고 있습니다... <<<
[2025-07-07 13:20:16][ERROR] [스레드 오류] recording_thread_func에서 예외 발생, 3초 후 재시작: The following operation failed in the TorchScript interpreter.
Traceback of TorchScript, serialized code (most recent call last):
  File "code/__torch__/vad/model/vad_annotator.py", line 26, in forward
    if _2:
      _3 = torch.format(_0, (torch.size(x0))[-1])
      ops.prim.RaiseException(_3, "builtins.ValueError")
      ~~~~~~~~~~~~~~~~~~~~~~~ <--- HERE
    else:
      pass

Traceback of TorchScript, original code (most recent call last):
  File "/home/keras/notebook/nvme1/adamnsandle/silero-models-research/vad/model/vad_annotator.py", line 480, in forward
        num_samples = 512 if sr == 16000 else 256
        if x.shape[-1] != num_samples:
            raise ValueError(f"Provided number of samples is {x.shape[-1]} (Supported values: 256 for 8000 sample rate, 512 for 16000)")
            ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ <--- HERE
    
        batch_size = x.shape[0]
builtins.ValueError: Provided number of samples is 1024 (Supported values: 256 for 8000 sample rate, 512 for 16000)

[2025-07-07 13:20:19][INFO] 
>>> AI VTuber가 당신의 말을 듣고 있습니다... <<<
[2025-07-07 13:20:19][ERROR] [스레드 오류] recording_thread_func에서 예외 발생, 3초 후 재시작: The following operation failed in the TorchScript interpreter.
Traceback of TorchScript, serialized code (most recent call last):
  File "code/__torch__/vad/model/vad_annotator.py", line 26, in forward
    if _2:
      _3 = torch.format(_0, (torch.size(x0))[-1])
      ops.prim.RaiseException(_3, "builtins.ValueError")
      ~~~~~~~~~~~~~~~~~~~~~~~ <--- HERE
    else:
      pass

Traceback of TorchScript, original code (most recent call last):
  File "/home/keras/notebook/nvme1/adamnsandle/silero-models-research/vad/model/vad_annotator.py", line 480, in forward
        num_samples = 512 if sr == 16000 else 256
        if x.shape[-1] != num_samples:
            raise ValueError(f"Provided number of samples is {x.shape[-1]} (Supported values: 256 for 8000 sample rate, 512 for 16000)")
            ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ <--- HERE
    
        batch_size = x.shape[0]
builtins.ValueError: Provided number of samples is 1024 (Supported values: 256 for 8000 sample rate, 512 for 16000)

[2025-07-07 13:20:22][INFO] 
>>> AI VTuber가 당신의 말을 듣고 있습니다... <<<
[2025-07-07 13:20:22][ERROR] [스레드 오류] recording_thread_func에서 예외 발생, 3초 후 재시작: The following operation failed in the TorchScript interpreter.
Traceback of TorchScript, serialized code (most recent call last):
  File "code/__torch__/vad/model/vad_annotator.py", line 26, in forward
    if _2:
      _3 = torch.format(_0, (torch.size(x0))[-1])
      ops.prim.RaiseException(_3, "builtins.ValueError")
      ~~~~~~~~~~~~~~~~~~~~~~~ <--- HERE
    else:
      pass

Traceback of TorchScript, original code (most recent call last):
  File "/home/keras/notebook/nvme1/adamnsandle/silero-models-research/vad/model/vad_annotator.py", line 480, in forward
        num_samples = 512 if sr == 16000 else 256
        if x.shape[-1] != num_samples:
            raise ValueError(f"Provided number of samples is {x.shape[-1]} (Supported values: 256 for 8000 sample rate, 512 for 16000)")
            ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ <--- HERE
    
        batch_size = x.shape[0]
builtins.ValueError: Provided number of samples is 1024 (Supported values: 256 for 8000 sample rate, 512 for 16000)

[2025-07-07 13:20:25][INFO] 
>>> AI VTuber가 당신의 말을 듣고 있습니다... <<<
[2025-07-07 13:20:25][ERROR] [스레드 오류] recording_thread_func에서 예외 발생, 3초 후 재시작: The following operation failed in the TorchScript interpreter.
Traceback of TorchScript, serialized code (most recent call last):
  File "code/__torch__/vad/model/vad_annotator.py", line 26, in forward
    if _2:
      _3 = torch.format(_0, (torch.size(x0))[-1])
      ops.prim.RaiseException(_3, "builtins.ValueError")
      ~~~~~~~~~~~~~~~~~~~~~~~ <--- HERE
    else:
      pass

Traceback of TorchScript, original code (most recent call last):
  File "/home/keras/notebook/nvme1/adamnsandle/silero-models-research/vad/model/vad_annotator.py", line 480, in forward
        num_samples = 512 if sr == 16000 else 256
        if x.shape[-1] != num_samples:
            raise ValueError(f"Provided number of samples is {x.shape[-1]} (Supported values: 256 for 8000 sample rate, 512 for 16000)")
            ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ <--- HERE
    
        batch_size = x.shape[0]
builtins.ValueError: Provided number of samples is 1024 (Supported values: 256 for 8000 sample rate, 512 for 16000)

[2025-07-07 13:20:28][INFO] 
>>> AI VTuber가 당신의 말을 듣고 있습니다... <<<
[2025-07-07 13:20:29][ERROR] [스레드 오류] recording_thread_func에서 예외 발생, 3초 후 재시작: The following operation failed in the TorchScript interpreter.
Traceback of TorchScript, serialized code (most recent call last):
  File "code/__torch__/vad/model/vad_annotator.py", line 26, in forward
    if _2:
      _3 = torch.format(_0, (torch.size(x0))[-1])
      ops.prim.RaiseException(_3, "builtins.ValueError")
      ~~~~~~~~~~~~~~~~~~~~~~~ <--- HERE
    else:
      pass

Traceback of TorchScript, original code (most recent call last):
  File "/home/keras/notebook/nvme1/adamnsandle/silero-models-research/vad/model/vad_annotator.py", line 480, in forward
        num_samples = 512 if sr == 16000 else 256
        if x.shape[-1] != num_samples:
            raise ValueError(f"Provided number of samples is {x.shape[-1]} (Supported values: 256 for 8000 sample rate, 512 for 16000)")
            ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ <--- HERE
    
        batch_size = x.shape[0]
builtins.ValueError: Provided number of samples is 1024 (Supported values: 256 for 8000 sample rate, 512 for 16000)

[2025-07-07 13:20:32][INFO] 
>>> AI VTuber가 당신의 말을 듣고 있습니다... <<<
[2025-07-07 13:20:32][ERROR] [스레드 오류] recording_thread_func에서 예외 발생, 3초 후 재시작: The following operation failed in the TorchScript interpreter.
Traceback of TorchScript, serialized code (most recent call last):
  File "code/__torch__/vad/model/vad_annotator.py", line 26, in forward
    if _2:
      _3 = torch.format(_0, (torch.size(x0))[-1])
      ops.prim.RaiseException(_3, "builtins.ValueError")
      ~~~~~~~~~~~~~~~~~~~~~~~ <--- HERE
    else:
      pass

Traceback of TorchScript, original code (most recent call last):
  File "/home/keras/notebook/nvme1/adamnsandle/silero-models-research/vad/model/vad_annotator.py", line 480, in forward
        num_samples = 512 if sr == 16000 else 256
        if x.shape[-1] != num_samples:
            raise ValueError(f"Provided number of samples is {x.shape[-1]} (Supported values: 256 for 8000 sample rate, 512 for 16000)")
            ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ <--- HERE
    
        batch_size = x.shape[0]
builtins.ValueError: Provided number of samples is 1024 (Supported values: 256 for 8000 sample rate, 512 for 16000)

[2025-07-07 13:20:35][INFO] 
>>> AI VTuber가 당신의 말을 듣고 있습니다... <<<
[2025-07-07 13:20:35][ERROR] [스레드 오류] recording_thread_func에서 예외 발생, 3초 후 재시작: The following operation failed in the TorchScript interpreter.
Traceback of TorchScript, serialized code (most recent call last):
  File "code/__torch__/vad/model/vad_annotator.py", line 26, in forward
    if _2:
      _3 = torch.format(_0, (torch.size(x0))[-1])
      ops.prim.RaiseException(_3, "builtins.ValueError")
      ~~~~~~~~~~~~~~~~~~~~~~~ <--- HERE
    else:
      pass

Traceback of TorchScript, original code (most recent call last):
  File "/home/keras/notebook/nvme1/adamnsandle/silero-models-research/vad/model/vad_annotator.py", line 480, in forward
        num_samples = 512 if sr == 16000 else 256
        if x.shape[-1] != num_samples:
            raise ValueError(f"Provided number of samples is {x.shape[-1]} (Supported values: 256 for 8000 sample rate, 512 for 16000)")
            ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ <--- HERE
    
        batch_size = x.shape[0]
builtins.ValueError: Provided number of samples is 1024 (Supported values: 256 for 8000 sample rate, 512 for 16000)

[2025-07-07 13:20:37][INFO] 프로그램을 종료합니다.
[2025-07-07 13:25:33][INFO] [환경 체크] 필수 의존성 및 설정 확인 완료.
[2025-07-07 13:25:33][INFO] 모든 AI 모델을 로드합니다. 시간이 걸릴 수 있습니다...
[2025-07-07 13:25:34][INFO] 1/5 - Silero VAD 모델 로드 완료.
[2025-07-07 13:25:34][INFO] 2/5 - Whisper STT 모델 로드 완료.
[2025-07-07 13:25:35][INFO] 3/5 - 감정 분석(Fast) 모델 로드 완료.
[2025-07-07 13:25:36][INFO] 4/5 - 감정 분석(Precise) 모델 로드 완료.
[2025-07-07 13:25:36][INFO] 5/5 - 로컬 LLM 모델 로드 완료.
[2025-07-07 13:25:36][INFO] --- 모든 모델 로드 완료 ---
[2025-07-07 13:25:36][INFO] 
>>> AI VTuber가 당신의 말을 듣고 있습니다... <<<
[2025-07-07 13:25:37][ERROR] [스레드 오류] recording_thread_func에서 예외 발생, 3초 후 재시작: The following operation failed in the TorchScript interpreter.
Traceback of TorchScript, serialized code (most recent call last):
  File "code/__torch__/vad/model/vad_annotator.py", line 26, in forward
    if _2:
      _3 = torch.format(_0, (torch.size(x0))[-1])
      ops.prim.RaiseException(_3, "builtins.ValueError")
      ~~~~~~~~~~~~~~~~~~~~~~~ <--- HERE
    else:
      pass

Traceback of TorchScript, original code (most recent call last):
  File "/home/keras/notebook/nvme1/adamnsandle/silero-models-research/vad/model/vad_annotator.py", line 480, in forward
        num_samples = 512 if sr == 16000 else 256
        if x.shape[-1] != num_samples:
            raise ValueError(f"Provided number of samples is {x.shape[-1]} (Supported values: 256 for 8000 sample rate, 512 for 16000)")
            ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ <--- HERE
    
        batch_size = x.shape[0]
builtins.ValueError: Provided number of samples is 1024 (Supported values: 256 for 8000 sample rate, 512 for 16000)

[2025-07-07 13:25:40][INFO] 
>>> AI VTuber가 당신의 말을 듣고 있습니다... <<<
[2025-07-07 13:25:40][ERROR] [스레드 오류] recording_thread_func에서 예외 발생, 3초 후 재시작: The following operation failed in the TorchScript interpreter.
Traceback of TorchScript, serialized code (most recent call last):
  File "code/__torch__/vad/model/vad_annotator.py", line 26, in forward
    if _2:
      _3 = torch.format(_0, (torch.size(x0))[-1])
      ops.prim.RaiseException(_3, "builtins.ValueError")
      ~~~~~~~~~~~~~~~~~~~~~~~ <--- HERE
    else:
      pass

Traceback of TorchScript, original code (most recent call last):
  File "/home/keras/notebook/nvme1/adamnsandle/silero-models-research/vad/model/vad_annotator.py", line 480, in forward
        num_samples = 512 if sr == 16000 else 256
        if x.shape[-1] != num_samples:
            raise ValueError(f"Provided number of samples is {x.shape[-1]} (Supported values: 256 for 8000 sample rate, 512 for 16000)")
            ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ <--- HERE
    
        batch_size = x.shape[0]
builtins.ValueError: Provided number of samples is 1024 (Supported values: 256 for 8000 sample rate, 512 for 16000)

[2025-07-07 13:25:43][INFO] 
>>> AI VTuber가 당신의 말을 듣고 있습니다... <<<
[2025-07-07 13:25:43][ERROR] [스레드 오류] recording_thread_func에서 예외 발생, 3초 후 재시작: The following operation failed in the TorchScript interpreter.
Traceback of TorchScript, serialized code (most recent call last):
  File "code/__torch__/vad/model/vad_annotator.py", line 26, in forward
    if _2:
      _3 = torch.format(_0, (torch.size(x0))[-1])
      ops.prim.RaiseException(_3, "builtins.ValueError")
      ~~~~~~~~~~~~~~~~~~~~~~~ <--- HERE
    else:
      pass

Traceback of TorchScript, original code (most recent call last):
  File "/home/keras/notebook/nvme1/adamnsandle/silero-models-research/vad/model/vad_annotator.py", line 480, in forward
        num_samples = 512 if sr == 16000 else 256
        if x.shape[-1] != num_samples:
            raise ValueError(f"Provided number of samples is {x.shape[-1]} (Supported values: 256 for 8000 sample rate, 512 for 16000)")
            ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ <--- HERE
    
        batch_size = x.shape[0]
builtins.ValueError: Provided number of samples is 1024 (Supported values: 256 for 8000 sample rate, 512 for 16000)

[2025-07-07 13:25:45][INFO] 프로그램을 종료합니다.
[2025-07-07 13:36:53][INFO] [환경 체크] 필수 의존성 및 설정 확인 완료.
[2025-07-07 13:36:53][INFO] 모든 AI 모델을 로드합니다. 시간이 걸릴 수 있습니다...
[2025-07-07 13:36:54][INFO] 1/5 - Silero VAD 모델 로드 완료.
[2025-07-07 13:36:55][INFO] 2/5 - Whisper STT 모델 로드 완료.
[2025-07-07 13:36:55][INFO] 3/5 - 감정 분석(Fast) 모델 로드 완료.
[2025-07-07 13:36:56][INFO] 4/5 - 감정 분석(Precise) 모델 로드 완료.
[2025-07-07 13:36:56][INFO] 5/5 - 로컬 LLM 모델 로드 완료.
[2025-07-07 13:36:56][INFO] --- 모든 모델 로드 완료 ---
[2025-07-07 13:36:56][INFO] 
>>> AI VTuber가 당신의 말을 듣고 있습니다... <<<
[2025-07-07 13:36:57][ERROR] [스레드 오류] recording_thread_func에서 예외 발생, 3초 후 재시작: The following operation failed in the TorchScript interpreter.
Traceback of TorchScript, serialized code (most recent call last):
  File "code/__torch__/vad/model/vad_annotator.py", line 26, in forward
    if _2:
      _3 = torch.format(_0, (torch.size(x0))[-1])
      ops.prim.RaiseException(_3, "builtins.ValueError")
      ~~~~~~~~~~~~~~~~~~~~~~~ <--- HERE
    else:
      pass

Traceback of TorchScript, original code (most recent call last):
  File "/home/keras/notebook/nvme1/adamnsandle/silero-models-research/vad/model/vad_annotator.py", line 480, in forward
        num_samples = 512 if sr == 16000 else 256
        if x.shape[-1] != num_samples:
            raise ValueError(f"Provided number of samples is {x.shape[-1]} (Supported values: 256 for 8000 sample rate, 512 for 16000)")
            ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ <--- HERE
    
        batch_size = x.shape[0]
builtins.ValueError: Provided number of samples is 1024 (Supported values: 256 for 8000 sample rate, 512 for 16000)

[2025-07-07 13:37:00][INFO] 
>>> AI VTuber가 당신의 말을 듣고 있습니다... <<<
[2025-07-07 13:37:00][ERROR] [스레드 오류] recording_thread_func에서 예외 발생, 3초 후 재시작: The following operation failed in the TorchScript interpreter.
Traceback of TorchScript, serialized code (most recent call last):
  File "code/__torch__/vad/model/vad_annotator.py", line 26, in forward
    if _2:
      _3 = torch.format(_0, (torch.size(x0))[-1])
      ops.prim.RaiseException(_3, "builtins.ValueError")
      ~~~~~~~~~~~~~~~~~~~~~~~ <--- HERE
    else:
      pass

Traceback of TorchScript, original code (most recent call last):
  File "/home/keras/notebook/nvme1/adamnsandle/silero-models-research/vad/model/vad_annotator.py", line 480, in forward
        num_samples = 512 if sr == 16000 else 256
        if x.shape[-1] != num_samples:
            raise ValueError(f"Provided number of samples is {x.shape[-1]} (Supported values: 256 for 8000 sample rate, 512 for 16000)")
            ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ <--- HERE
    
        batch_size = x.shape[0]
builtins.ValueError: Provided number of samples is 1024 (Supported values: 256 for 8000 sample rate, 512 for 16000)

[2025-07-07 13:37:03][INFO] 
>>> AI VTuber가 당신의 말을 듣고 있습니다... <<<
[2025-07-07 13:37:03][ERROR] [스레드 오류] recording_thread_func에서 예외 발생, 3초 후 재시작: The following operation failed in the TorchScript interpreter.
Traceback of TorchScript, serialized code (most recent call last):
  File "code/__torch__/vad/model/vad_annotator.py", line 26, in forward
    if _2:
      _3 = torch.format(_0, (torch.size(x0))[-1])
      ops.prim.RaiseException(_3, "builtins.ValueError")
      ~~~~~~~~~~~~~~~~~~~~~~~ <--- HERE
    else:
      pass

Traceback of TorchScript, original code (most recent call last):
  File "/home/keras/notebook/nvme1/adamnsandle/silero-models-research/vad/model/vad_annotator.py", line 480, in forward
        num_samples = 512 if sr == 16000 else 256
        if x.shape[-1] != num_samples:
            raise ValueError(f"Provided number of samples is {x.shape[-1]} (Supported values: 256 for 8000 sample rate, 512 for 16000)")
            ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ <--- HERE
    
        batch_size = x.shape[0]
builtins.ValueError: Provided number of samples is 1024 (Supported values: 256 for 8000 sample rate, 512 for 16000)

[2025-07-07 13:37:03][INFO] 프로그램을 종료합니다.
[2025-07-07 13:37:40][INFO] [환경 체크] 필수 의존성 및 설정 확인 완료.
[2025-07-07 13:37:40][INFO] 모든 AI 모델을 로드합니다. 시간이 걸릴 수 있습니다...
[2025-07-07 13:37:41][INFO] 1/5 - Silero VAD 모델 로드 완료.
[2025-07-07 13:37:42][INFO] 2/5 - Whisper STT 모델 로드 완료.
[2025-07-07 13:37:42][INFO] 3/5 - 감정 분석(Fast) 모델 로드 완료.
[2025-07-07 13:37:44][INFO] 4/5 - 감정 분석(Precise) 모델 로드 완료.
[2025-07-07 13:37:44][INFO] 5/5 - 로컬 LLM 모델 로드 완료.
[2025-07-07 13:37:44][INFO] --- 모든 모델 로드 완료 ---
[2025-07-07 13:37:44][INFO] 
>>> AI VTuber가 당신의 말을 듣고 있습니다... <<<
[2025-07-07 13:37:44][ERROR] [스레드 오류] recording_thread_func에서 예외 발생, 3초 후 재시작: The following operation failed in the TorchScript interpreter.
Traceback of TorchScript, serialized code (most recent call last):
  File "code/__torch__/vad/model/vad_annotator.py", line 26, in forward
    if _2:
      _3 = torch.format(_0, (torch.size(x0))[-1])
      ops.prim.RaiseException(_3, "builtins.ValueError")
      ~~~~~~~~~~~~~~~~~~~~~~~ <--- HERE
    else:
      pass

Traceback of TorchScript, original code (most recent call last):
  File "/home/keras/notebook/nvme1/adamnsandle/silero-models-research/vad/model/vad_annotator.py", line 480, in forward
        num_samples = 512 if sr == 16000 else 256
        if x.shape[-1] != num_samples:
            raise ValueError(f"Provided number of samples is {x.shape[-1]} (Supported values: 256 for 8000 sample rate, 512 for 16000)")
            ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ <--- HERE
    
        batch_size = x.shape[0]
builtins.ValueError: Provided number of samples is 1024 (Supported values: 256 for 8000 sample rate, 512 for 16000)

[2025-07-07 13:37:47][INFO] 
>>> AI VTuber가 당신의 말을 듣고 있습니다... <<<
[2025-07-07 13:37:47][ERROR] [스레드 오류] recording_thread_func에서 예외 발생, 3초 후 재시작: The following operation failed in the TorchScript interpreter.
Traceback of TorchScript, serialized code (most recent call last):
  File "code/__torch__/vad/model/vad_annotator.py", line 26, in forward
    if _2:
      _3 = torch.format(_0, (torch.size(x0))[-1])
      ops.prim.RaiseException(_3, "builtins.ValueError")
      ~~~~~~~~~~~~~~~~~~~~~~~ <--- HERE
    else:
      pass

Traceback of TorchScript, original code (most recent call last):
  File "/home/keras/notebook/nvme1/adamnsandle/silero-models-research/vad/model/vad_annotator.py", line 480, in forward
        num_samples = 512 if sr == 16000 else 256
        if x.shape[-1] != num_samples:
            raise ValueError(f"Provided number of samples is {x.shape[-1]} (Supported values: 256 for 8000 sample rate, 512 for 16000)")
            ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ <--- HERE
    
        batch_size = x.shape[0]
builtins.ValueError: Provided number of samples is 1024 (Supported values: 256 for 8000 sample rate, 512 for 16000)

[2025-07-07 13:37:47][INFO] 프로그램을 종료합니다.
[2025-07-07 13:39:24][INFO] [환경 체크] 필수 의존성 및 설정 확인 완료.
[2025-07-07 13:39:24][INFO] 모든 AI 모델을 로드합니다. 시간이 걸릴 수 있습니다...
[2025-07-07 13:39:24][INFO] 1/5 - Silero VAD 모델 로드 완료.
[2025-07-07 13:39:25][INFO] 2/5 - Whisper STT 모델 로드 완료.
[2025-07-07 13:39:26][INFO] 3/5 - 감정 분석(Fast) 모델 로드 완료.
[2025-07-07 13:39:27][INFO] 4/5 - 감정 분석(Precise) 모델 로드 완료.
[2025-07-07 13:39:27][INFO] 5/5 - 로컬 LLM 모델 로드 완료.
[2025-07-07 13:39:27][INFO] --- 모든 모델 로드 완료 ---
[2025-07-07 13:39:27][INFO] 
>>> AI VTuber가 당신의 말을 듣고 있습니다... <<<
[2025-07-07 13:39:27][ERROR] [스레드 오류] recording_thread_func에서 예외 발생, 3초 후 재시작: The following operation failed in the TorchScript interpreter.
Traceback of TorchScript, serialized code (most recent call last):
  File "code/__torch__/vad/model/vad_annotator.py", line 26, in forward
    if _2:
      _3 = torch.format(_0, (torch.size(x0))[-1])
      ops.prim.RaiseException(_3, "builtins.ValueError")
      ~~~~~~~~~~~~~~~~~~~~~~~ <--- HERE
    else:
      pass

Traceback of TorchScript, original code (most recent call last):
  File "/home/keras/notebook/nvme1/adamnsandle/silero-models-research/vad/model/vad_annotator.py", line 480, in forward
        num_samples = 512 if sr == 16000 else 256
        if x.shape[-1] != num_samples:
            raise ValueError(f"Provided number of samples is {x.shape[-1]} (Supported values: 256 for 8000 sample rate, 512 for 16000)")
            ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ <--- HERE
    
        batch_size = x.shape[0]
builtins.ValueError: Provided number of samples is 1024 (Supported values: 256 for 8000 sample rate, 512 for 16000)

[2025-07-07 13:39:30][INFO] 
>>> AI VTuber가 당신의 말을 듣고 있습니다... <<<
[2025-07-07 13:39:30][ERROR] [스레드 오류] recording_thread_func에서 예외 발생, 3초 후 재시작: The following operation failed in the TorchScript interpreter.
Traceback of TorchScript, serialized code (most recent call last):
  File "code/__torch__/vad/model/vad_annotator.py", line 26, in forward
    if _2:
      _3 = torch.format(_0, (torch.size(x0))[-1])
      ops.prim.RaiseException(_3, "builtins.ValueError")
      ~~~~~~~~~~~~~~~~~~~~~~~ <--- HERE
    else:
      pass

Traceback of TorchScript, original code (most recent call last):
  File "/home/keras/notebook/nvme1/adamnsandle/silero-models-research/vad/model/vad_annotator.py", line 480, in forward
        num_samples = 512 if sr == 16000 else 256
        if x.shape[-1] != num_samples:
            raise ValueError(f"Provided number of samples is {x.shape[-1]} (Supported values: 256 for 8000 sample rate, 512 for 16000)")
            ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ <--- HERE
    
        batch_size = x.shape[0]
builtins.ValueError: Provided number of samples is 1024 (Supported values: 256 for 8000 sample rate, 512 for 16000)

[2025-07-07 13:39:32][INFO] 프로그램을 종료합니다.
[2025-07-07 13:40:34][INFO] [환경 체크] 필수 의존성 및 설정 확인 완료.
[2025-07-07 13:40:34][INFO] 모든 AI 모델을 로드합니다. 시간이 걸릴 수 있습니다...
[2025-07-07 13:40:35][INFO] 1/5 - Silero VAD 모델 로드 완료.
[2025-07-07 13:40:35][INFO] 2/5 - Whisper STT 모델 로드 완료.
[2025-07-07 13:40:36][INFO] 3/5 - 감정 분석(Fast) 모델 로드 완료.
[2025-07-07 13:40:37][INFO] 4/5 - 감정 분석(Precise) 모델 로드 완료.
[2025-07-07 13:40:37][INFO] 5/5 - 로컬 LLM 모델 로드 완료.
[2025-07-07 13:40:37][INFO] --- 모든 모델 로드 완료 ---
[2025-07-07 13:40:37][INFO] 
>>> AI VTuber가 당신의 말을 듣고 있습니다... <<<
[2025-07-07 13:40:38][ERROR] [스레드 오류] recording_thread_func에서 예외 발생, 3초 후 재시작: The following operation failed in the TorchScript interpreter.
Traceback of TorchScript, serialized code (most recent call last):
  File "code/__torch__/vad/model/vad_annotator.py", line 26, in forward
    if _2:
      _3 = torch.format(_0, (torch.size(x0))[-1])
      ops.prim.RaiseException(_3, "builtins.ValueError")
      ~~~~~~~~~~~~~~~~~~~~~~~ <--- HERE
    else:
      pass

Traceback of TorchScript, original code (most recent call last):
  File "/home/keras/notebook/nvme1/adamnsandle/silero-models-research/vad/model/vad_annotator.py", line 480, in forward
        num_samples = 512 if sr == 16000 else 256
        if x.shape[-1] != num_samples:
            raise ValueError(f"Provided number of samples is {x.shape[-1]} (Supported values: 256 for 8000 sample rate, 512 for 16000)")
            ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ <--- HERE
    
        batch_size = x.shape[0]
builtins.ValueError: Provided number of samples is 1024 (Supported values: 256 for 8000 sample rate, 512 for 16000)

[2025-07-07 13:40:41][INFO] 
>>> AI VTuber가 당신의 말을 듣고 있습니다... <<<
[2025-07-07 13:40:41][ERROR] [스레드 오류] recording_thread_func에서 예외 발생, 3초 후 재시작: The following operation failed in the TorchScript interpreter.
Traceback of TorchScript, serialized code (most recent call last):
  File "code/__torch__/vad/model/vad_annotator.py", line 26, in forward
    if _2:
      _3 = torch.format(_0, (torch.size(x0))[-1])
      ops.prim.RaiseException(_3, "builtins.ValueError")
      ~~~~~~~~~~~~~~~~~~~~~~~ <--- HERE
    else:
      pass

Traceback of TorchScript, original code (most recent call last):
  File "/home/keras/notebook/nvme1/adamnsandle/silero-models-research/vad/model/vad_annotator.py", line 480, in forward
        num_samples = 512 if sr == 16000 else 256
        if x.shape[-1] != num_samples:
            raise ValueError(f"Provided number of samples is {x.shape[-1]} (Supported values: 256 for 8000 sample rate, 512 for 16000)")
            ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ <--- HERE
    
        batch_size = x.shape[0]
builtins.ValueError: Provided number of samples is 1024 (Supported values: 256 for 8000 sample rate, 512 for 16000)

[2025-07-07 13:40:42][INFO] 프로그램을 종료합니다.
